{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89a6114",
   "metadata": {},
   "source": [
    "# Forex News Analysis for BIG DREAMS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b3f8c",
   "metadata": {},
   "source": [
    "![pic](Forexpic.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f09a18",
   "metadata": {},
   "source": [
    "# Project Overview \n",
    "\n",
    "This project is a fusion of machine learning and time series forecasting techniques aimed at predicting the sentiment (positive or negative) of Forex news articles. By combining traditional machine learning models and the Facebook Prophet time series forecasting model, the project provides insights into how news impacts the foreign exchange market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b984b8",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "Predicting the influence of Forex news articles is vital for traders and investors looking to forecast market movements driven by economic events. The project addresses this challenge by developing two predictive modelsâ€”one centered on machine learning and another leveraging time series forecasting. These models offer actionable insights to guide trading strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9585e8",
   "metadata": {},
   "source": [
    "### Columns Overview:\n",
    "\n",
    "- `Date`: Date of the news article\n",
    "- `ISM Manufacturing PMI`: Institute for Supply Management Manufacturing Purchasing Managers Index\n",
    "- `ISM Services PMI`: Institute for Supply Management Non-Manufacturing Purchasing Managers Index\n",
    "- `Housing Starts`: Number of housing construction projects started\n",
    "- `Non-Farm Employment Change`: Change in the number of employed people\n",
    "- `Unemployment Rate`: Percentage of unemployed individuals in the labor force\n",
    "- `Consumer Price Index (CPI)`: Measure of inflation\n",
    "- `Producer Price Index (PPI)`: Measure of average change in selling prices\n",
    "- `Retail Sales`: Total retail sales of consumer goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fcdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV file into dataframe\n",
    "df = pd.read_csv('Forex Fundumental News For USD.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b63878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check info of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad97462",
   "metadata": {},
   "source": [
    "- data is completely clean\n",
    "- will need to change the varibles labled as object to numerical because they are numerical values being listed as not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in the DataFrame\n",
    "# Further investigation of the missing values\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "ax = sns.heatmap(df.isna().sum().to_frame(),annot=True,fmt='d',cmap='crest')\n",
    "ax.set_xlabel('Null Values', fontdict = {'fontsize': 15})\n",
    "ax.set_ylabel('Predictors', fontdict = {'fontsize': 15})\n",
    "ax.set_title('Null Values', fontweight='bold', fontdict = {'fontsize': 18})\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013de3a",
   "metadata": {},
   "source": [
    "- no null values in the data set whatsoever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d694303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated rows in the DataFrame\n",
    "duplicated_rows = df.duplicated()\n",
    "\n",
    "if any(duplicated_rows):\n",
    "    print(\"\\nDuplicated rows:\")\n",
    "    print(df[duplicated_rows])\n",
    "else:\n",
    "    print(\"No duplicated rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eae1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
    "\n",
    "# Convert 'Housing Starts' column to numerical values and rename\n",
    "df['Housing Starts (M)'] = df['Housing Starts'].str.rstrip('M').astype(float)\n",
    "\n",
    "# Convert 'Non-Farm Employment Change' column to numerical values and rename\n",
    "df['Non-Farm Employment Ch (k)'] = df['Non-Farm Employment Change'].str.rstrip('K').astype(float)\n",
    "\n",
    "# Convert 'Unemployment Rate ' column to numerical values and rename\n",
    "df['Unemployment Rate (%)'] = df['Unemployment  Rate'].str.rstrip('%').astype(float)\n",
    "\n",
    "# Convert 'Unemployment Rate ' column to numerical values and rename\n",
    "df['Retail Sales (%)'] = df['Retail Sales'].str.rstrip('%').astype(float)\n",
    "\n",
    "# Convert 'Producer Price Index (PPI)' column to numerical values and rename\n",
    "df['Producer Price Index (PPI) (%)'] = df['Producer Price Index (PPI)'].str.rstrip('%').astype(float)\n",
    "\n",
    "# Convert 'Consumer Price Index (CPI)' column to numerical values and rename\n",
    "df['Consumer Price Index (CPI) (%)'] = df['Consumer Price Index (CPI)'].str.rstrip('%').astype(float)\n",
    "\n",
    "# List the column names for plotting (excluding 'Date', original columns)\n",
    "column_names = df.columns.difference(['Date', 'Housing Starts', 'Non-Farm Employment Change', 'Consumer Price Index (CPI)',\n",
    "                                      'Producer Price Index (PPI)', 'Retail Sales', 'Unemployment  Rate'])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e64db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the modified DataFrame\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595ba66",
   "metadata": {},
   "source": [
    "- in order for the data to be trained for machine learning the columns labeled as object will need to be changed to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the specified columns to float\n",
    "columns_to_convert = [\n",
    "    'Housing Starts', 'Non-Farm Employment Change', 'Unemployment  Rate',\n",
    "    'Consumer Price Index (CPI)', 'Producer Price Index (PPI)', 'Retail Sales'\n",
    "]\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    df[column] = df[column].str.replace('[^\\d.-]', '', regex=True).astype(float)\n",
    "\n",
    "# List the column names for plotting (excluding 'Date', original columns)\n",
    "column_names = df.columns.difference(['Date', 'Housing Starts', 'Non-Farm Employment Change', 'Consumer Price Index (CPI)',\n",
    "                                      'Producer Price Index (PPI)', 'Retail Sales', 'Unemployment  Rate'])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfebaea",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbcdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set larger figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each column in separate plots\n",
    "for column in column_names:\n",
    "    plt.figure(figsize=(10, 6))  # Create a new figure for each column\n",
    "    plt.plot(df['Date'], df[column], marker='o', color='firebrick')\n",
    "    plt.title(f'{column} Over Time', fontsize=16)\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Value', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "   \n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f958f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Create a heatmap of correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddffeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to plot\n",
    "columns_to_plot = [\n",
    "    'ISM Manufacturing PMI', 'ISM Services PMI', 'Housing Starts',\n",
    "    'Non-Farm Employment Change', 'Unemployment  Rate',\n",
    "    'Consumer Price Index (CPI)', 'Producer Price Index (PPI)',\n",
    "    'Retail Sales'\n",
    "]\n",
    "\n",
    "# Create a custom colormap from red to green\n",
    "colors = [(1, 0, 0), (0, 1, 0)]\n",
    "cmap = LinearSegmentedColormap.from_list('RedGreen', colors, N=256)\n",
    "\n",
    "# Normalize the colors based on values\n",
    "norm = mcolors.Normalize(vmin=-1, vmax=1)\n",
    "\n",
    "# Create a plot for each column showing positive/negative values over time\n",
    "for column in columns_to_plot:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Color mapping: green for positive values, red for negative values\n",
    "    colors = [cmap(norm(val)) for val in df[column]]\n",
    "    \n",
    "    plt.scatter(df['Date'], df[column], c=colors, marker='o')\n",
    "    \n",
    "    plt.title(f'{column} Positive/Negative Values Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(column)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add colorbar legend ranging from red (negative) to green (positive)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, orientation='vertical')\n",
    "    cbar.set_label('Colorbar Legend')\n",
    "    \n",
    "    # Add grid\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c6dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to analyze\n",
    "columns_to_analyze = [\n",
    "    'ISM Manufacturing PMI', 'ISM Services PMI', 'Housing Starts',\n",
    "    'Non-Farm Employment Change', 'Unemployment  Rate',\n",
    "    'Consumer Price Index (CPI)', 'Producer Price Index (PPI)',\n",
    "    'Retail Sales']\n",
    "\n",
    "# Analyze whether values are positive or negative for each column\n",
    "for column in columns_to_analyze:\n",
    "    positive_count = df[df[column] > 0].shape[0]\n",
    "    negative_count = df[df[column] < 0].shape[0]\n",
    "    \n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Positive Count: {positive_count}\")\n",
    "    print(f\"Negative Count: {negative_count}\")\n",
    "    \n",
    "    if positive_count > negative_count:\n",
    "        print(\"More Positive\")\n",
    "    elif positive_count < negative_count:\n",
    "        print(\"More Negative\")\n",
    "    else:\n",
    "        print(\"Equal Positive and Negative\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362c69b",
   "metadata": {},
   "source": [
    "- From the plot and the summary above you can see that from 2010 to present, most of the news over time has been positive with a few negative values in the PPI, CPI and retail sales columns. \n",
    "\n",
    "- Will attempt to use this information to project whether the news will be positive or negative going forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fbb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for each numerical column\n",
    "plt.figure(figsize=(16, 10))  # Increased figure size\n",
    "colors = sns.color_palette(\"Set3\", n_colors=len(df.columns) - 1)  # Choose a color palette\n",
    "sns.boxplot(data=df.drop(['Date'], axis=1), palette=colors)  # Use the chosen palette\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Box Plots of Numerical Columns')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pair plots for selected numerical columns\n",
    "sns.pairplot(df[['Housing Starts', 'Non-Farm Employment Change', 'Unemployment  Rate']])\n",
    "plt.suptitle('Pair Plots of Selected Columns', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fcb95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pair plots for selected numerical columns\n",
    "sns.pairplot(df[['ISM Manufacturing PMI', 'ISM Services PMI']])\n",
    "plt.suptitle('Pair Plots of Selected Columns', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db6a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pair plots for selected numerical columns\n",
    "sns.pairplot(df[['Consumer Price Index (CPI)', 'Producer Price Index (PPI)',\n",
    "    'Retail Sales']])\n",
    "plt.suptitle('Pair Plots of Selected Columns', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for each numerical column\n",
    "plt.figure(figsize=(12, 8))\n",
    "df.drop(['Date'], axis=1).hist(bins=20, figsize=(12, 8))\n",
    "plt.suptitle('Histograms of Numerical Columns', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3c7eb",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3df5f1",
   "metadata": {},
   "source": [
    "Feature engineering can enhance the predictive power of the model by creating new relevant features from the existing data. In the context of economic indicators and time series data, here are a few feature engineering ideas that might help improve the model's performance:\n",
    "\n",
    "- Lagged Values: Include lagged values of the economic indicators as features. For instance, you can include the values of the indicators from the past few days or months as predictors. This can capture temporal dependencies and patterns in the data.\n",
    "\n",
    "\n",
    "- Moving Averages: Compute moving averages of the indicators over different time windows. Moving averages can help smooth out noise and highlight trends.\n",
    "\n",
    "\n",
    "- Differences: Calculate the differences between consecutive values of the indicators. This can capture changes in trends over time.\n",
    "\n",
    "\n",
    "- Percentage Changes: Compute the percentage changes between consecutive values. This can help capture the magnitude of changes relative to the previous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to analyze\n",
    "columns_to_analyze = [\n",
    "    'ISM Manufacturing PMI', 'ISM Services PMI', 'Housing Starts',\n",
    "    'Non-Farm Employment Change', 'Unemployment  Rate',\n",
    "    'Consumer Price Index (CPI)', 'Producer Price Index (PPI)',\n",
    "    'Retail Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe7b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "for column in columns_to_analyze:\n",
    "    # Lagged values\n",
    "    df[f'{column}_lag_1'] = df[column].shift(1)\n",
    "    df[f'{column}_lag_2'] = df[column].shift(2)\n",
    "    \n",
    "    # Visualize lagged values\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    sns.lineplot(data=df[[column, f'{column}_lag_1', f'{column}_lag_2']])\n",
    "    plt.title(f'{column} and Lagged Values Visualization', fontsize=24)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend([column, f'{column}_lag_1', f'{column}_lag_2'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Moving averages\n",
    "    df[f'{column}_ma_3'] = df[column].rolling(window=3).mean()\n",
    "    df[f'{column}_ma_7'] = df[column].rolling(window=7).mean()\n",
    "    \n",
    "    # Visualize moving averages\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    sns.lineplot(data=df[[column, f'{column}_ma_3', f'{column}_ma_7']])\n",
    "    plt.title(f'{column} and Moving Averages Visualization', fontsize=24)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend([column, f'{column}_ma_3', f'{column}_ma_7'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Differences\n",
    "    df[f'{column}_diff'] = df[column].diff()\n",
    "    \n",
    "    # Visualize differences\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    sns.lineplot(data=df[[f'{column}_diff']])\n",
    "    plt.title(f'{column} Differences Visualization', fontsize=24)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'{column} Difference')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Percentage changes\n",
    "    df[f'{column}_pct_change'] = df[column].pct_change()\n",
    "    \n",
    "    # Visualize percentage changes\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    sns.lineplot(data=df[[f'{column}_pct_change']])\n",
    "    plt.title(f'{column} Percentage Changes Visualization', fontsize=24)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'{column} Percentage Change')\n",
    "    plt.xticks(rotation=45, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd647a",
   "metadata": {},
   "source": [
    "# Model Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite or very large values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# List of columns to analyze\n",
    "columns_to_analyze = [\n",
    "    'ISM Manufacturing PMI', 'ISM Services PMI', 'Housing Starts',\n",
    "    'Non-Farm Employment Change', 'Unemployment  Rate',\n",
    "    'Consumer Price Index (CPI)', 'Producer Price Index (PPI)',\n",
    "    'Retail Sales'\n",
    "]\n",
    "\n",
    "# Create target variables\n",
    "for column in columns_to_analyze:\n",
    "    df[f'{column}_target'] = np.where(df[column] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1472931d",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f08458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-Test Split\n",
    "features = [f'{column}_{feat}' for column in columns_to_analyze for feat in ['lag_1', 'lag_2', 'ma_3', 'ma_7', 'diff', 'pct_change']]\n",
    "target_columns = [f'{column}_target' for column in columns_to_analyze]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target_columns]\n",
    "\n",
    "# Separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=None, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea58f7",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9bdf7d",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aece7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models_rf = {}\n",
    "scaler_rf = StandardScaler()\n",
    "X_train_scaled_rf = scaler_rf.fit_transform(X_train)\n",
    "for column in columns_to_analyze:\n",
    "    y_train_column = y_train[f'{column}_target']\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train_scaled_rf, y_train_column)\n",
    "    \n",
    "    models_rf[column] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e7e8d7",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092055f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models_knn = {}\n",
    "scaler_knn = StandardScaler()\n",
    "X_train_scaled_knn = scaler_knn.fit_transform(X_train)\n",
    "for column in columns_to_analyze:\n",
    "    y_train_column = y_train[f'{column}_target']\n",
    "    \n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(X_train_scaled_knn, y_train_column)\n",
    "    \n",
    "    models_knn[column] = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca14a62d",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ced012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "models = {\n",
    "    'Random Forest': models_rf,\n",
    "    'KNN': models_knn\n",
    "}\n",
    "\n",
    "for model_name, model_dict in models.items():\n",
    "    print(f\"Evaluating {model_name} model...\")\n",
    "    for column, model in model_dict.items():\n",
    "        X_test_scaled = None\n",
    "        if model_name == 'Random Forest':\n",
    "            X_test_scaled = scaler_rf.transform(X_test)\n",
    "        elif model_name == 'KNN':\n",
    "            X_test_scaled = scaler_knn.transform(X_test)\n",
    "        \n",
    "        y_test_column = y_test[f'{column}_target']\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        print(f\"Results for column: {column}\")\n",
    "        print(classification_report(y_test_column, y_pred))\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc39e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "look_back_period = 30  # Set the desired look-back period\n",
    "\n",
    "future_df = df[-look_back_period:]  # Replace with desired look-back period\n",
    "\n",
    "# Initialize a dictionary to store future predictions\n",
    "future_predictions = {}\n",
    "\n",
    "for model_name, model_dict in models.items():\n",
    "    model_predictions = {}\n",
    "    \n",
    "    for column, model in model_dict.items():\n",
    "        X_future_scaled = None\n",
    "        if model_name == 'Random Forest':\n",
    "            X_future_scaled = scaler_rf.transform(future_df[features])\n",
    "        elif model_name == 'KNN':\n",
    "            X_future_scaled = scaler_knn.transform(future_df[features])\n",
    "        \n",
    "        future_predictions[column] = model.predict(X_future_scaled)\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "future_predictions_df = pd.DataFrame(future_predictions, index=future_df.index)\n",
    "\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(12, 8))\n",
    "for column in columns_to_analyze:\n",
    "    plt.plot(future_predictions_df.index, future_predictions_df[column], marker='o', label=column)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Predicted Positive/Negative')\n",
    "plt.title('Predicted Positive/Negative Values Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "positive_counts = future_predictions_df.eq(1).sum()\n",
    "negative_counts = future_predictions_df.eq(0).sum()\n",
    "\n",
    "plt.bar(positive_counts.index, positive_counts, label='Positive', color='g')\n",
    "plt.bar(negative_counts.index, negative_counts, label='Negative', color='r')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Positive/Negative Predictions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da022c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.violinplot(data=future_predictions_df, inner='quartiles', palette=['g', 'r'])\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Predicted Positive/Negative')\n",
    "plt.title('Distribution of Predicted Positive/Negative Values')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb24277",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for column in columns_to_analyze:\n",
    "    positive_count = (future_predictions_df[column] == 1).sum()\n",
    "    negative_count = (future_predictions_df[column] == 0).sum()\n",
    "    \n",
    "    # Set colors for positive and negative segments\n",
    "    colors = ['g', 'r']\n",
    "    \n",
    "    plt.pie([positive_count, negative_count], labels=['Positive', 'Negative'], autopct='%1.1f%%', startangle=140, colors=colors)\n",
    "    plt.title(f'Proportion of Positive/Negative Predictions for {column}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dba576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "# List of columns to analyze\n",
    "columns_to_analyze = [\n",
    "    'ISM Manufacturing PMI', 'ISM Services PMI', 'Housing Starts',\n",
    "    'Non-Farm Employment Change', 'Unemployment  Rate',\n",
    "    'Consumer Price Index (CPI)', 'Producer Price Index (PPI)',\n",
    "    'Retail Sales'\n",
    "]\n",
    "\n",
    "# Train a Prophet model for each column\n",
    "prophet_models = {}\n",
    "for column in columns_to_analyze:\n",
    "    train_data = df[['Date', column]]\n",
    "    train_data = train_data.rename(columns={'Date': 'ds', column: 'y'})\n",
    "\n",
    "    model = Prophet()\n",
    "    model.fit(train_data)\n",
    "    prophet_models[column] = model\n",
    "\n",
    "# Predictions for each column on a specific date\n",
    "for column in columns_to_analyze:\n",
    "    print(f\"Enter a future date (YYYY-MM-DD) for {column}: \")\n",
    "    future_date = input()\n",
    "    \n",
    "    future_df = pd.DataFrame({'ds': [future_date]})\n",
    "    \n",
    "    model = prophet_models[column]\n",
    "    forecast = model.predict(future_df)\n",
    "    predicted_sentiment = 'Positive' if forecast['yhat'].iloc[0] > 0 else 'Negative'\n",
    "    \n",
    "    print(f\"Predicted sentiment for {column} on {future_date}: {predicted_sentiment}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba293bd",
   "metadata": {},
   "source": [
    "- This here was a test of entering a random date of when the news will take place and the prediction outputing whether the news will be negative or positive on that day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc423a",
   "metadata": {},
   "source": [
    "# Limitations & Next Steps\n",
    "\n",
    "The models have limitations, including the potential influence of external factors not captured in the dataset and the need for real-time data integration. Future steps may involve improving model accuracy by incorporating real-time data, refining feature engineering techniques, and building an interactive platform to provide real-time sentiment predictions for traders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64330065",
   "metadata": {},
   "source": [
    "# Observations & Conclusions\n",
    "\n",
    "This project seamlessly combines machine learning and time series forecasting to predict the sentiment of Forex news articles. By integrating these two approaches, it offers comprehensive insights into the influence of economic indicators and events on the foreign exchange market. These insights empower traders with valuable information to make informed decisions and devise effective trading strategies.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
